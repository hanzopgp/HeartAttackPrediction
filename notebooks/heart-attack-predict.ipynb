{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom sklearn import preprocessing\nimport pandas as pd\nimport time\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\"\nVALID_SPLIT = 0.1\nTEST_SPLIT = 0.1\nFEATURES = [\"age\", \"sex\", \"cp\", \"trtbps\", \"chol\", \"fbs\", \"restecg\", \"thalachh\", \"exng\", \"oldpeak\", \"slp\", \"caa\", \"thall\"]\nN_FEATURES = len(FEATURES)\nEPOCHS = 500\nNB_NEURONS = 4096\nDROPOUT_VALUE = 0.3","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/heart-attack-analysis-prediction-dataset/o2Saturation.csv\n/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess():\n    data = pd.read_csv(DATA_PATH)\n    base_data = data\n    preprocess_data = pd.DataFrame(np.array([]))\n    for col in data.columns:\n        if col != \"output\":\n            preprocess_data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n        else:\n            preprocess_data[col] = data[col]\n    print(data[\"output\"].value_counts())\n    return base_data, preprocess_data","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"base_data, preprocess_data = preprocess()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1    165\n0    138\nName: output, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocess_data.describe().transpose()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"          count      mean       std  min       25%       50%       75%  max\n0           0.0       NaN       NaN  NaN       NaN       NaN       NaN  NaN\nage       303.0  0.528465  0.189210  0.0  0.385417  0.541667  0.666667  1.0\nsex       303.0  0.683168  0.466011  0.0  0.000000  1.000000  1.000000  1.0\ncp        303.0  0.322332  0.344017  0.0  0.000000  0.333333  0.666667  1.0\ntrtbps    303.0  0.354941  0.165454  0.0  0.245283  0.339623  0.433962  1.0\nchol      303.0  0.274575  0.118335  0.0  0.194064  0.260274  0.339041  1.0\nfbs       303.0  0.148515  0.356198  0.0  0.000000  0.000000  0.000000  1.0\nrestecg   303.0  0.264026  0.262930  0.0  0.000000  0.500000  0.500000  1.0\nthalachh  303.0  0.600358  0.174849  0.0  0.477099  0.625954  0.725191  1.0\nexng      303.0  0.326733  0.469794  0.0  0.000000  0.000000  1.000000  1.0\noldpeak   303.0  0.167678  0.187270  0.0  0.000000  0.129032  0.258065  1.0\nslp       303.0  0.699670  0.308113  0.0  0.500000  0.500000  1.000000  1.0\ncaa       303.0  0.182343  0.255652  0.0  0.000000  0.000000  0.250000  1.0\nthall     303.0  0.771177  0.204092  0.0  0.666667  0.666667  1.000000  1.0\noutput    303.0  0.544554  0.498835  0.0  0.000000  1.000000  1.000000  1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>303.0</td>\n      <td>0.528465</td>\n      <td>0.189210</td>\n      <td>0.0</td>\n      <td>0.385417</td>\n      <td>0.541667</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>303.0</td>\n      <td>0.683168</td>\n      <td>0.466011</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>cp</th>\n      <td>303.0</td>\n      <td>0.322332</td>\n      <td>0.344017</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>trtbps</th>\n      <td>303.0</td>\n      <td>0.354941</td>\n      <td>0.165454</td>\n      <td>0.0</td>\n      <td>0.245283</td>\n      <td>0.339623</td>\n      <td>0.433962</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>chol</th>\n      <td>303.0</td>\n      <td>0.274575</td>\n      <td>0.118335</td>\n      <td>0.0</td>\n      <td>0.194064</td>\n      <td>0.260274</td>\n      <td>0.339041</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>fbs</th>\n      <td>303.0</td>\n      <td>0.148515</td>\n      <td>0.356198</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>restecg</th>\n      <td>303.0</td>\n      <td>0.264026</td>\n      <td>0.262930</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>thalachh</th>\n      <td>303.0</td>\n      <td>0.600358</td>\n      <td>0.174849</td>\n      <td>0.0</td>\n      <td>0.477099</td>\n      <td>0.625954</td>\n      <td>0.725191</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>exng</th>\n      <td>303.0</td>\n      <td>0.326733</td>\n      <td>0.469794</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>oldpeak</th>\n      <td>303.0</td>\n      <td>0.167678</td>\n      <td>0.187270</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.129032</td>\n      <td>0.258065</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>slp</th>\n      <td>303.0</td>\n      <td>0.699670</td>\n      <td>0.308113</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>caa</th>\n      <td>303.0</td>\n      <td>0.182343</td>\n      <td>0.255652</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>thall</th>\n      <td>303.0</td>\n      <td>0.771177</td>\n      <td>0.204092</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>output</th>\n      <td>303.0</td>\n      <td>0.544554</td>\n      <td>0.498835</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_tmp, valid_data = train_test_split(preprocess_data, test_size=VALID_SPLIT)\ntrain_data, test_data = train_test_split(data_tmp, test_size=TEST_SPLIT)","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(valid_data.shape)\nprint(test_data.shape)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(244, 15)\n(31, 15)\n(28, 15)\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Dense(N_FEATURES, input_shape=train_data[FEATURES].shape, activation=\"linear\"))\n    model.add(Dense(NB_NEURONS, activation=\"relu\"))\n    model.add(Dropout(DROPOUT_VALUE))\n    model.add(Dense(NB_NEURONS, activation=\"relu\"))\n    model.add(Dropout(DROPOUT_VALUE))\n    model.add(Dense(NB_NEURONS, activation=\"relu\"))\n    model.add(Dropout(DROPOUT_VALUE))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n    model.summary()\n    return model","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_callbacks():   \n\n    early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 50 , verbose = 1, restore_best_weights = True)\n    \n    model_cp = ModelCheckpoint('model.h5', \n                                 save_best_only = True, \n                                 save_weights_only = True,\n                                 monitor = 'val_loss', \n                                 mode = 'min', verbose = 1)\n    \n    return [early_stopping, model_cp]","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 244, 13)           182       \n_________________________________________________________________\ndense_1 (Dense)              (None, 244, 4096)         57344     \n_________________________________________________________________\ndropout (Dropout)            (None, 244, 4096)         0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 244, 4096)         16781312  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 244, 4096)         0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 244, 4096)         16781312  \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 244, 4096)         0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 244, 1)            4097      \n=================================================================\nTotal params: 33,624,247\nTrainable params: 33,624,247\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train_data[FEATURES], train_data[\"output\"], \n                    epochs=EPOCHS, \n                    validation_data=(valid_data[FEATURES], valid_data[\"output\"]),\n                    callbacks = get_callbacks())","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/500\n8/8 [==============================] - 2s 96ms/step - loss: 0.6916 - accuracy: 0.4976 - val_loss: 0.6908 - val_accuracy: 0.5806\n\nEpoch 00001: val_loss improved from inf to 0.69084, saving model to model.h5\nEpoch 2/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5850 - val_loss: 0.6880 - val_accuracy: 0.8387\n\nEpoch 00002: val_loss improved from 0.69084 to 0.68799, saving model to model.h5\nEpoch 3/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.6282 - val_loss: 0.6850 - val_accuracy: 0.7097\n\nEpoch 00003: val_loss improved from 0.68799 to 0.68505, saving model to model.h5\nEpoch 4/500\n8/8 [==============================] - 0s 14ms/step - loss: 0.6847 - accuracy: 0.7192 - val_loss: 0.6826 - val_accuracy: 0.6774\n\nEpoch 00004: val_loss improved from 0.68505 to 0.68255, saving model to model.h5\nEpoch 5/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.7165 - val_loss: 0.6800 - val_accuracy: 0.6452\n\nEpoch 00005: val_loss improved from 0.68255 to 0.67999, saving model to model.h5\nEpoch 6/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.6964 - val_loss: 0.6773 - val_accuracy: 0.6452\n\nEpoch 00006: val_loss improved from 0.67999 to 0.67732, saving model to model.h5\nEpoch 7/500\n8/8 [==============================] - 0s 16ms/step - loss: 0.6783 - accuracy: 0.6882 - val_loss: 0.6748 - val_accuracy: 0.6452\n\nEpoch 00007: val_loss improved from 0.67732 to 0.67481, saving model to model.h5\nEpoch 8/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.7532 - val_loss: 0.6724 - val_accuracy: 0.6452\n\nEpoch 00008: val_loss improved from 0.67481 to 0.67236, saving model to model.h5\nEpoch 9/500\n8/8 [==============================] - 0s 17ms/step - loss: 0.6729 - accuracy: 0.7853 - val_loss: 0.6697 - val_accuracy: 0.6452\n\nEpoch 00009: val_loss improved from 0.67236 to 0.66974, saving model to model.h5\nEpoch 10/500\n8/8 [==============================] - 0s 11ms/step - loss: 0.6721 - accuracy: 0.7661 - val_loss: 0.6673 - val_accuracy: 0.6452\n\nEpoch 00010: val_loss improved from 0.66974 to 0.66726, saving model to model.h5\nEpoch 11/500\n8/8 [==============================] - 0s 13ms/step - loss: 0.6675 - accuracy: 0.7454 - val_loss: 0.6648 - val_accuracy: 0.6452\n\nEpoch 00011: val_loss improved from 0.66726 to 0.66476, saving model to model.h5\nEpoch 12/500\n8/8 [==============================] - 0s 11ms/step - loss: 0.6648 - accuracy: 0.7473 - val_loss: 0.6621 - val_accuracy: 0.6452\n\nEpoch 00012: val_loss improved from 0.66476 to 0.66213, saving model to model.h5\nEpoch 13/500\n8/8 [==============================] - 0s 14ms/step - loss: 0.6627 - accuracy: 0.7491 - val_loss: 0.6596 - val_accuracy: 0.6452\n\nEpoch 00013: val_loss improved from 0.66213 to 0.65957, saving model to model.h5\nEpoch 14/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6608 - accuracy: 0.7592 - val_loss: 0.6569 - val_accuracy: 0.6452\n\nEpoch 00014: val_loss improved from 0.65957 to 0.65690, saving model to model.h5\nEpoch 15/500\n8/8 [==============================] - 0s 11ms/step - loss: 0.6574 - accuracy: 0.7260 - val_loss: 0.6541 - val_accuracy: 0.6452\n\nEpoch 00015: val_loss improved from 0.65690 to 0.65411, saving model to model.h5\nEpoch 16/500\n8/8 [==============================] - 0s 14ms/step - loss: 0.6563 - accuracy: 0.7612 - val_loss: 0.6514 - val_accuracy: 0.6452\n\nEpoch 00016: val_loss improved from 0.65411 to 0.65144, saving model to model.h5\nEpoch 17/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6534 - accuracy: 0.7606 - val_loss: 0.6487 - val_accuracy: 0.6452\n\nEpoch 00017: val_loss improved from 0.65144 to 0.64874, saving model to model.h5\nEpoch 18/500\n8/8 [==============================] - 0s 13ms/step - loss: 0.6498 - accuracy: 0.7689 - val_loss: 0.6459 - val_accuracy: 0.6452\n\nEpoch 00018: val_loss improved from 0.64874 to 0.64592, saving model to model.h5\nEpoch 19/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6445 - accuracy: 0.7699 - val_loss: 0.6432 - val_accuracy: 0.6452\n\nEpoch 00019: val_loss improved from 0.64592 to 0.64318, saving model to model.h5\nEpoch 20/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6451 - accuracy: 0.7448 - val_loss: 0.6402 - val_accuracy: 0.6452\n\nEpoch 00020: val_loss improved from 0.64318 to 0.64021, saving model to model.h5\nEpoch 21/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6380 - accuracy: 0.7771 - val_loss: 0.6372 - val_accuracy: 0.6774\n\nEpoch 00021: val_loss improved from 0.64021 to 0.63723, saving model to model.h5\nEpoch 22/500\n8/8 [==============================] - 0s 13ms/step - loss: 0.6395 - accuracy: 0.7581 - val_loss: 0.6341 - val_accuracy: 0.6774\n\nEpoch 00022: val_loss improved from 0.63723 to 0.63413, saving model to model.h5\nEpoch 23/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6391 - accuracy: 0.7588 - val_loss: 0.6310 - val_accuracy: 0.6774\n\nEpoch 00023: val_loss improved from 0.63413 to 0.63105, saving model to model.h5\nEpoch 24/500\n8/8 [==============================] - 0s 14ms/step - loss: 0.6312 - accuracy: 0.7512 - val_loss: 0.6278 - val_accuracy: 0.6774\n\nEpoch 00024: val_loss improved from 0.63105 to 0.62776, saving model to model.h5\nEpoch 25/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6271 - accuracy: 0.7473 - val_loss: 0.6246 - val_accuracy: 0.6774\n\nEpoch 00025: val_loss improved from 0.62776 to 0.62455, saving model to model.h5\nEpoch 26/500\n8/8 [==============================] - 0s 11ms/step - loss: 0.6253 - accuracy: 0.7539 - val_loss: 0.6213 - val_accuracy: 0.6774\n\nEpoch 00026: val_loss improved from 0.62455 to 0.62129, saving model to model.h5\nEpoch 27/500\n8/8 [==============================] - 0s 13ms/step - loss: 0.6184 - accuracy: 0.7498 - val_loss: 0.6180 - val_accuracy: 0.6774\n\nEpoch 00027: val_loss improved from 0.62129 to 0.61796, saving model to model.h5\nEpoch 28/500\n8/8 [==============================] - 0s 11ms/step - loss: 0.6189 - accuracy: 0.7478 - val_loss: 0.6147 - val_accuracy: 0.6774\n\nEpoch 00028: val_loss improved from 0.61796 to 0.61470, saving model to model.h5\nEpoch 29/500\n8/8 [==============================] - 0s 13ms/step - loss: 0.6182 - accuracy: 0.7193 - val_loss: 0.6112 - val_accuracy: 0.6774\n\nEpoch 00029: val_loss improved from 0.61470 to 0.61115, saving model to model.h5\nEpoch 30/500\n8/8 [==============================] - 0s 18ms/step - loss: 0.6015 - accuracy: 0.8080 - val_loss: 0.6076 - val_accuracy: 0.6774\n\nEpoch 00030: val_loss improved from 0.61115 to 0.60761, saving model to model.h5\nEpoch 31/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6097 - accuracy: 0.7222 - val_loss: 0.6039 - val_accuracy: 0.6774\n\nEpoch 00031: val_loss improved from 0.60761 to 0.60387, saving model to model.h5\nEpoch 32/500\n8/8 [==============================] - 0s 12ms/step - loss: 0.6025 - accuracy: 0.7644 - val_loss: 0.6002 - val_accuracy: 0.6774\n\nEpoch 00032: val_loss improved from 0.60387 to 0.60023, saving model to model.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"#Train set data\nloss_curve = history.history[\"loss\"]\nacc_curve = history.history[\"accuracy\"]\n\n#Validation set data\nval_loss_curve = history.history[\"val_loss\"]\nval_acc_curve = history.history[\"val_accuracy\"]\n\n#Loss plot\nplt.plot(loss_curve, label=\"Train set\")\nplt.plot(val_loss_curve, label=\"Validation set\")\nplt.legend(loc='upper right')\nplt.title(\"Loss\")\nplt.show()\n\n#Accuracy plot\nplt.plot(acc_curve, label=\"Train set\")\nplt.plot(val_acc_curve, label=\"Validation set\")\nplt.legend(loc='lower right')\nplt.title(\"Accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_data[FEATURES])\nfor prediction in predictions:\n    if prediction > 0.5:\n        print(\"Risky\")\n    else:\n        print(\"Safe\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}